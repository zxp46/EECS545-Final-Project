{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "from time import time\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    torchvision.datasets.MNIST(\n",
    "        \"data/MNIST\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.5, ), std=(0.5,))])\n",
    "    ),\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Opt(object):\n",
    "    n_epochs = 40\n",
    "    Diters = 5\n",
    "    batchSize = 128\n",
    "    lr = 0.00005\n",
    "    n_cpu = 1\n",
    "    latent_dim = 100\n",
    "    imageSize = 32\n",
    "    channels = 1\n",
    "    n_critic = 5\n",
    "    experiment = \"experiments\"\n",
    "    sample_interval = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight initialization\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_channel = 100,\n",
    "             out_channel = 1,\n",
    "             feature_map = 128,\n",
    "             kernal_size = 3,\n",
    "             image_size = 28):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        #Upsample random variable\n",
    "        layers = nn.ModuleList()\n",
    "        layers += [nn.ConvTranspose2d(in_channel, feature_map, 4, 1, 0)]\n",
    "        layers += [nn.BatchNorm2d(feature_map)]\n",
    "        layers += [nn.ReLU(True)]\n",
    "        \n",
    "        size = 4\n",
    "        \n",
    "        layers += [nn.ConvTranspose2d(feature_map, feature_map // 2, kernal_size, 2, 1, bias = False)]\n",
    "        layers += [nn.BatchNorm2d(feature_map // 2)]\n",
    "        layers += [nn.ReLU(True)]\n",
    "        feature_map = feature_map // 2\n",
    "        size = size * 2\n",
    "        \n",
    "        #Main G structure\n",
    "        while size < image_size // 2:\n",
    "            layers += [nn.ConvTranspose2d(feature_map, feature_map // 2, 4, 2, 1, bias = False)]\n",
    "            layers += [nn.BatchNorm2d(feature_map // 2)]\n",
    "            layers += [nn.ReLU(True)]\n",
    "            feature_map = feature_map // 2\n",
    "            size = size * 2\n",
    "        \n",
    "        #Final layer\n",
    "        layers += [nn.ConvTranspose2d(feature_map, out_channel, 4, 2, 1, bias = False)]\n",
    "        layers += [nn.Tanh()]\n",
    "        \n",
    "        self.g = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        return self.g(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channel = 1,\n",
    "             out_channel = 1,\n",
    "             feature_map = 32,\n",
    "             kernal_size = 3,\n",
    "             image_size = 28):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        #First layer\n",
    "        layers = nn.ModuleList()\n",
    "        layers += [nn.Conv2d(in_channel, feature_map, 4, 2, 1)]\n",
    "        layers += [nn.BatchNorm2d(feature_map)]\n",
    "        layers += [nn.LeakyReLU(0.2, inplace=True)]\n",
    "        \n",
    "        size = image_size / 2\n",
    "        \n",
    "        #Main D structure\n",
    "        while size > 8:\n",
    "            layers += [nn.Conv2d(feature_map, feature_map * 2, 4, 2, 1, bias = False)]\n",
    "            layers += [nn.BatchNorm2d(feature_map * 2)]\n",
    "            layers += [nn.LeakyReLU(0.2, inplace=True)]\n",
    "            feature_map = feature_map * 2\n",
    "            size = size / 2\n",
    "            \n",
    "        layers += [nn.Conv2d(feature_map, feature_map * 2, kernal_size, 2, 1, bias = False)]\n",
    "        layers += [nn.BatchNorm2d(feature_map * 2)]\n",
    "        layers += [nn.LeakyReLU(0.2, inplace=True)]\n",
    "        feature_map = feature_map * 2\n",
    "        size = size / 2\n",
    "        \n",
    "        #Final layer\n",
    "        layers += [nn.Conv2d(feature_map, out_channel, 4, 1, 0, bias = False)]\n",
    "        \n",
    "        self.d = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        return self.d(image)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Opt()\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "generator_optimizer = torch.optim.RMSprop(generator.parameters(), lr=opt.lr)\n",
    "discriminator_optimizer = torch.optim.RMSprop(discriminator.parameters(), lr=opt.lr)\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_done = 0\n",
    "saved_imgs = []\n",
    "input = torch.FloatTensor(opt.batchSize, 1, opt.imageSize, opt.imageSize)\n",
    "noise = torch.FloatTensor(opt.batchSize, opt.latent_dim)\n",
    "fixed_noise = torch.FloatTensor(opt.batchSize, opt.latent_dim).normal_(0, 1)\n",
    "one = torch.FloatTensor([1])\n",
    "mone = one * -1\n",
    "\n",
    "gen_iterations = 0\n",
    "for epoch in range(opt.n_epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "        real_imgs = real_imgs.to(device)\n",
    "        for _ in range(opt.Diters):\n",
    "            noise = torch.randn(opt.batchSize,opt.latent_dim, 1,1,device=device)\n",
    "            fake = generator(noise).detach()\n",
    "            errD_fake = torch.mean(discriminator(fake))\n",
    "            errD_real = torch.mean(discriminator(real_imgs))\n",
    "            errD = errD_fake - errD_real\n",
    "            discriminator.zero_grad()\n",
    "            errD.backward()\n",
    "            discriminator_optimizer.step()\n",
    "            for p in discriminator.parameters():\n",
    "                p.data.clamp_(-0.01, 0.01)\n",
    "                \n",
    "        gen_fake = generator(noise)\n",
    "        errG = -torch.mean(discriminator(gen_fake))        \n",
    "        generator.zero_grad()\n",
    "        errG.backward()\n",
    "        generator_optimizer.step()\n",
    "        gen_iterations += 1\n",
    "\n",
    "        print('[%d/%d][%d/%d][%d] Loss_D: %f Loss_G: %f Loss_D_real: %f Loss_D_fake %f'\n",
    "            % (epoch, opt.n_epochs, i, len(dataloader), gen_iterations,\n",
    "            errD.item(), errG.item(), errD_real.item(), errD_fake.item()))\n",
    "        if gen_iterations % 300 == 0:\n",
    "            real_imgs = real_imgs.mul(0.5).add(0.5)\n",
    "            save_image(real_imgs, '{0}/real_samples.png'.format(opt.experiment))\n",
    "            with torch.no_grad():\n",
    "                fake = generator(noise)\n",
    "            fake.data = fake.data.mul(0.5).add(0.5)\n",
    "            save_image(fake.data, '{0}/fake_samples_{1}.png'.format(opt.experiment, gen_iterations))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
